from dotenv import load_dotenv
import os
from pydantic import BaseModel, Field, ValidationError
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from anthropic import BadRequestError
from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from langchain.agents import create_tool_calling_agent, AgentExecutor
from tools import search_tool,wiki_tool,save_tool
# from langchain.agents import create_openai_functions_agent


load_dotenv()

class ResearchResponse(BaseModel):
    topic: str
    summary: str
    sources: list[str]
    tools_used: list[str] 

# llm=ChatOpenAI(model="gpt-4o-mini")

# llm2 = ChatOpenAI(
#     model="deepseek-chat",
#     api_key=os.getenv("DEEPSEEK_API_KEY"),
#     base_url="https://openrouter.ai/api/v1",
# )
llm2 = ChatOpenAI(
    model="deepseek/deepseek-chat",          
    api_key=os.getenv("DEEPSEEK_API_KEY"),  
    base_url="https://openrouter.ai/api/v1",
)

# print("Loaded key:", os.getenv("ANTHROPIC_API_KEY"))  # check if it's loaded

parser = PydanticOutputParser(pydantic_object=ResearchResponse)

response = llm2.invoke("What is the capital of France?")
print(response.content)

# print("sofkokfor")


prompt = ChatPromptTemplate.from_messages([
    ("system", """
        You are a research assistent that will help generate a research paper. 
        Answer the user query and use neccessary tools.
        Wrap the output in this format and provide no other text:
        \n{format_instructions}.
    """),
    ("placeholder", "{chat_history}"),
    ("human", "{Query}"),
    ("placeholder", "{agent_scratchpad}")
]).partial(format_instructions=parser.get_format_instructions())

tools=[search_tool,wiki_tool,save_tool]
# cars

# for tool in tools:
# print(f"Tool available: {tool.name} - {tool.description}")

agent = create_tool_calling_agent(
    llm=llm2,
    tools=tools,
    prompt=prompt
    # output_parser=parser
)

agent_executor = AgentExecutor.from_agent_and_tools(
    agent=agent,
    tools=tools,
    verbose=True,
)
while True:
    query = input("What can I help you? ")
    if query.lower() in ["exit","quit","q"]:
        break
    raw_response = agent_executor.invoke({"Query": query})
    # print("Raw response:", raw_response)
    # print("Agent tools:", [tool.name for tool in agent_executor.tools])

    try:
        structured_response = parser.parse(raw_response.get("output",raw_response))#["output"])
        print(structured_response)
        # print("Agent tools:", [tool.name for tool in agent_executor.tools])
        print("\n---------------------------------------------------------------------------\n")

    except Exception as e:
        print("Error parsing response:", e, "Raw response",raw_response)

# raw_response = agent_executor.invoke({"Query": "Provide a detailed search about Egyptian history."})
# print("Raw response:", raw_response)